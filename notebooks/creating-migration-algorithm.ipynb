{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Migration Algorithm\n",
    "\n",
    "This tutorial demonstrates how we can create a simple migration algorithm on EdgeSimPy.\n",
    "\n",
    "First, let's import the EdgeSimPy modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Importing EdgeSimPy components\n",
    "    from edge_sim_py import *\n",
    "    import networkx as nx\n",
    "    import msgpack\n",
    "\n",
    "    # Importing Matplotlib, Pandas, and NumPy for logs parsing and visualization\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "    # Downloading EdgeSimPy binaries from GitHub (the \"-q\" parameter suppresses Pip's output. You check the full logs by removing it)\n",
    "    %pip install -q git+https://github.com/EdgeSimPy/EdgeSimPy.git@v1.1.0\n",
    "\n",
    "    # Downloading Pandas, NumPy, and Matplotlib (these are not directly used here, but they can be useful for logs parsing and visualization)\n",
    "    %pip install -q pandas==1.3.5\n",
    "    %pip install -q numpy==1.26.4\n",
    "    %pip install -q matplotlib==3.5.0\n",
    "\n",
    "    # Importing EdgeSimPy components and its built-in libraries (NetworkX and MessagePack)\n",
    "    from edge_sim_py import *\n",
    "    import networkx as nx\n",
    "    import msgpack\n",
    "\n",
    "    # Importing Matplotlib, Pandas, and NumPy for logs parsing and visualization\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the Migration Algorithm\n",
    "\n",
    "Our simple migration algorithm will work according to the well-known Worst-Fit heuristic. In a nutshell, it will provision each service to the edge server with the largest amount of free resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_algorithm(parameters):\n",
    "    # Let's iterate over the list of services using the 'all()' helper method\n",
    "    print(\"\\n\\n\")\n",
    "    print(f\"==== TIME STEP {parameters['current_step']} ====\")\n",
    "    print(\"---- EDGE SERVERS ----\")\n",
    "    for server in EdgeServer.all():\n",
    "        server_metadata = {\n",
    "            \"server\": server,\n",
    "            \"capacity\": [server.cpu, server.memory, server.disk],\n",
    "            \"demand\": [server.cpu_demand, server.memory_demand, server.disk_demand],\n",
    "            \"container_layers\": [layer.id for layer in server.container_layers],\n",
    "            \"services\": [service for service in server.services],\n",
    "        }\n",
    "        print(server_metadata)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"---- SERVICES ----\")\n",
    "    for service in Service.all():\n",
    "        service_image = ContainerImage.find_by(attribute_name=\"digest\", attribute_value=service.image_digest)\n",
    "        service_layers = [ContainerLayer.find_by(attribute_name=\"digest\", attribute_value=layer).id for layer in service_image.layers_digests]\n",
    "\n",
    "        service_metadata = {\n",
    "            \"service\": service,\n",
    "            \"requirements\": [service.cpu_demand, service.memory_demand],\n",
    "            \"layers\": service_layers,\n",
    "            \"server\": service.server,\n",
    "            \"available\": service._available,\n",
    "            \"being_provisioned\": service.being_provisioned,\n",
    "        }\n",
    "        print(service_metadata)\n",
    "\n",
    "    # We don't want to migrate services are are already being migrated. As we want to avoid excessive migrations, we are going to\n",
    "    # define a cool down period for services that have been migrated. For simplicity, we are going to set the cool down period as\n",
    "    # 10 time steps. To get such information, we are going to access the service's last migration time step and compare it with\n",
    "    # the current time step. If the difference between the current time step and the last migration time step is less than 10,\n",
    "    # we are going to skip the service.\n",
    "    COOLDOWN_STEPS = 10\n",
    "\n",
    "    for service in Service.all():\n",
    "        # Gathering the current time step and the last migration time step of the service\n",
    "        current_step = parameters[\"current_step\"]\n",
    "        \n",
    "        if len(service._Service__migrations) > 0 and service._Service__migrations[-1][\"end\"] is not None:\n",
    "            last_migration_ended_at = service._Service__migrations[-1][\"end\"]\n",
    "        else:\n",
    "            last_migration_ended_at = None\n",
    "\n",
    "        # Checking if the service is not being provisioned and if the cool down period has being reached\n",
    "        service_has_not_been_migrated_yet = len(service._Service__migrations) == 0\n",
    "        service_not_being_provisioned = service.being_provisioned is False\n",
    "        cooldown_has_been_reached = last_migration_ended_at is not None and current_step - last_migration_ended_at >= COOLDOWN_STEPS\n",
    "\n",
    "        if service_has_not_been_migrated_yet or service_not_being_provisioned and cooldown_has_been_reached:\n",
    "            # We need to sort edge servers based on amount of free resources they have. To do so, we are going to use Python's\n",
    "            # \"sorted\" method (you can learn more about \"sorted()\" in this link: https://docs.python.org/3/howto/sorting.html).\n",
    "            # The capacity of edge servers is modeled in three layers (CPU, memory, and disk). For simplicity, we are going to\n",
    "            # use only the CPU layer to sort edge servers. We calculate the free CPU resources of each edge server by subtracting\n",
    "            # the CPU demand of the services hosted in the edge server from the total CPU capacity of the edge server. We then\n",
    "            # sort edge servers based on their free CPU resources. To do so, we use the \"sorted\" method and set the \"key\" attribute\n",
    "            # as a lambda function that calculates the free CPU resources of edge servers. We set the \"reverse\" attribute as \"True\"\n",
    "            # as we want to sort edge servers by their free CPU resources in descending order.\n",
    "            edge_servers = sorted(\n",
    "                EdgeServer.all(),\n",
    "                key=lambda s: s.cpu - s.cpu_demand,\n",
    "                reverse=True,\n",
    "            )\n",
    "\n",
    "            for edge_server in edge_servers:\n",
    "                # Checking if the edge server has resources to host the service\n",
    "                if edge_server.has_capacity_to_host(service=service):\n",
    "                    # We just need to migrate the service if it's not already in the least occupied edge server\n",
    "                    if service.server != edge_server:\n",
    "                        print(f\"\\t\\t[STEP {parameters['current_step']}] Migrating {service} From {service.server} to {edge_server}\")\n",
    "\n",
    "                        service.provision(target_server=edge_server)\n",
    "\n",
    "                        # After start migrating the service we can move on to the next service\n",
    "                        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Simulation\n",
    "\n",
    "Before testing our algorithm, we must tell EdgeSimPy when it must stop the simulation. For example, let's run the simulation for 600 seconds (i.e., 10 minutes).\n",
    "\n",
    "To do so, we must create a simple function that will be used as the simulation's stopping criterion. Behind the scenes, at the end of each time step, EdgeSimPy will run that function, halting the simulation if it returns `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopping_criterion(model: object):    \n",
    "    # As EdgeSimPy will halt the simulation whenever this function returns True,\n",
    "    # its output will be a boolean expression that checks if the current time step is 600\n",
    "    return model.schedule.steps == 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have developed our stopping criterion function, we can create an instance of the `Simulation` class passing a couple of arguments, load a dataset, and run the simulation to check how our algorithm goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Simulator object\n",
    "simulator = Simulator(\n",
    "    tick_duration=1,\n",
    "    tick_unit=\"seconds\",\n",
    "    stopping_criterion=stopping_criterion,\n",
    "    resource_management_algorithm=my_algorithm,\n",
    ")\n",
    "\n",
    "# Loading a sample dataset from GitHub\n",
    "simulator.initialize(input_file=\"https://raw.githubusercontent.com/EdgeSimPy/edgesimpy-tutorials/master/datasets/sample_dataset1.json\")\n",
    "\n",
    "# Executing the simulation\n",
    "simulator.run_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('edgesimpy-tutorials-QsXmQ38W-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50cb211c4021f4a25a142368b69ce4d994f94aff73dc90314b4ffb0c06ad024a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
